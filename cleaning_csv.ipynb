{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Location\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change clean to trump or hillary\n",
    "clean = \"hillary\"\n",
    "\n",
    "hillary_id = \"1_O34ymqlI_vZT8DOC0rWEanIitY-f_Ua\"\n",
    "trump_id = \"1la94BAiQdNx2_foAtoZPtD_GxvKNi63c\"\n",
    "\n",
    "if clean == \"hillary\":\n",
    "    download_id = hillary_id\n",
    "else:\n",
    "    download_id = trump_id\n",
    "\n",
    "parent_csv = \"data/scraper/%s.csv\" % clean\n",
    "users_csv = \"data/script/%s_users.csv\" % clean\n",
    "log = \"data/script/%s_log\" % clean\n",
    "\n",
    "if not os.path.isfile(parent_csv):\n",
    "    download_file_from_google_drive(download_id, parent_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(users_csv):\n",
    "    # Import CSV\n",
    "    df_parent = pd.read_csv(parent_csv,sep=';')\n",
    "\n",
    "    # Delete Duplicates\n",
    "    df_parent = df_parent.drop_duplicates(subset='id')\n",
    "\n",
    "    # Create DF of unique users\n",
    "    df_users = df_parent[['userid','user']].drop_duplicates(subset='userid')\n",
    "    df_users['userid'] = df_users['userid'].fillna(-1).astype(int)\n",
    "    df_users['loc'] = np.nan\n",
    "    df_users['lat'] = np.nan\n",
    "    df_users['lon'] = np.nan\n",
    "    \n",
    "    # Save to csv\n",
    "    df_users.to_csv(users_csv,index=False)\n",
    "else:\n",
    "    df_users = pd.read_csv(users_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLocation(user):\n",
    "    uid, usr, loc, lat, lon = user\n",
    "    url = \"https://twitter.com/%s\" % usr\n",
    "    try:\n",
    "        if not pd.isnull(loc):\n",
    "            #print(\"location present\")\n",
    "            pass\n",
    "        else:\n",
    "            content = requests.get(url)\n",
    "            soup = BeautifulSoup(content.text)\n",
    "            span = soup.find(\"span\", class_=\"ProfileHeaderCard-locationText u-dir\")\n",
    "            if span is None:\n",
    "                raise AttributeError(\"invalid user\")\n",
    "            loc = span.text.strip()\n",
    "            if loc == '':\n",
    "                loc = np.nan\n",
    "                raise ValueError(\"no location\")\n",
    "            elif len(loc) == 2:\n",
    "                loc += ',USA'\n",
    "                \n",
    "    except Exception as e:\n",
    "        saveError(user, e)\n",
    "\n",
    "    user[2] = loc\n",
    "    if not pd.isnull(loc):\n",
    "        lat, lon = convertGeo(user)\n",
    "    return loc, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertGeo(user):\n",
    "    uid, usr, loc, lat, lon = user\n",
    "    try:\n",
    "        if not pd.isnull(lat):\n",
    "            #print(\"coordinates present\")\n",
    "            pass\n",
    "        else:\n",
    "            geolocator = Nominatim(country_bias=\"United States of America\")\n",
    "            place = geolocator.geocode(loc,addressdetails=True)\n",
    "            if place is None:\n",
    "                raise ValueError(\"invalid location\")\n",
    "            elif place.raw['address']['country'] != 'United States of America':\n",
    "                #print(place.raw['address']['country'])\n",
    "                raise ValueError(\"location not USA\")\n",
    "            else:\n",
    "                lat = place.latitude\n",
    "                lon = place.longitude\n",
    "    \n",
    "    except Exception as e:\n",
    "        saveError(user, e)\n",
    "\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveError(user, text):\n",
    "    uid, usr, loc, lat, lon = user\n",
    "    t = [uid,usr,loc,lat,lon,text]\n",
    "    df = pd.DataFrame(columns=['uid','usr','loc','lat','lon','err'])\n",
    "    df.loc[0] = t\n",
    "    # print(t)\n",
    "    if not os.path.isfile(log):\n",
    "        with open(log, 'w') as f:\n",
    "            df.to_csv(f, index=False)\n",
    "    else:\n",
    "        with open(log, 'a') as f:\n",
    "            df.to_csv(f, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "size = 10000\n",
    "for chunk in range(27):\n",
    "    print(chunk)\n",
    "    df_temp = df_users[chunk*size:(chunk+1)*size]\n",
    "    df_temp[['loc','lat','lon']] = df_temp.apply(lambda x: findLocation(x), axis=1).apply(pd.Series)\n",
    "    df_users[chunk*size:(chunk+1)*size] = df_temp\n",
    "    with open(users_csv, 'w') as f:\n",
    "        df_users.to_csv(f, index=False)\n",
    "\n",
    "# do for last chunk\n",
    "chunk += 1\n",
    "df_temp = df_users[chunk*size:]\n",
    "df_temp[['loc','lat','lon']] = df_temp.apply(lambda x: findLocation(x), axis=1).apply(pd.Series)\n",
    "df_users[chunk*size:] = df_temp\n",
    "with open(users_csv, 'w') as f:\n",
    "    df_users.to_csv(f, index=False)\n",
    "\n",
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
